import SwiftUI
import AVFoundation
import AudioToolbox
/// Un gestionnaire qui cr√©e une boucle audio (loopback) entre l'entr√©e microphone et la sortie audio.
///
/// Cette classe utilise Core Audio pour √©tablir une connexion directe entre le microphone
/// et les haut-parleurs, permettant de rediriger l'audio captur√© vers la sortie en temps r√©el.
class AudioLoopbackManager: ObservableObject {
    /// L'instance AudioUnit utilis√©e pour le traitement audio.
    var audioUnit: AudioComponentInstance?
    
    /// Initialise le gestionnaire de loopback audio.
    ///
    /// Configure la session audio et initialise l'AudioUnit n√©cessaire pour
    /// √©tablir la connexion entre l'entr√©e et la sortie audio.
    init() {
        setupAudioSession()
        setupAudioUnit()
    }
    
    /// Configure la session audio pour permettre l'enregistrement et la lecture simultan√©s.
    ///
    /// D√©finit la cat√©gorie de session audio sur `.playAndRecord` avec les options
    /// pour utiliser le haut-parleur par d√©faut et permettre les p√©riph√©riques Bluetooth.
    private func setupAudioSession() {
        let session = AVAudioSession.sharedInstance()
        do {
            try session.setCategory(.playAndRecord, options: [.defaultToSpeaker, .allowBluetooth])
            try session.setActive(true)
        } catch {
            print("Erreur lors de la configuration de l'AVAudioSession : \(error)")
        }
    }
    
    /// Configure l'AudioUnit pour le traitement audio en temps r√©el.
    ///
    /// Cette m√©thode:
    /// 1. Cr√©e une description de composant audio pour le RemoteIO
    /// 2. Trouve et initialise le composant audio correspondant
    /// 3. Active l'entr√©e et la sortie audio
    /// 4. Configure le format audio pour l'entr√©e et la sortie
    /// 5. √âtablit la connexion entre l'entr√©e et la sortie via un callback de rendu
    /// 6. Initialise et d√©marre l'AudioUnit
    private func setupAudioUnit() {
        // Cr√©ation de la description du composant audio pour RemoteIO
        var desc = AudioComponentDescription(componentType: kAudioUnitType_Output,
                                             componentSubType: kAudioUnitSubType_RemoteIO,
                                             componentManufacturer: kAudioUnitManufacturer_Apple,
                                             componentFlags: 0,
                                             componentFlagsMask: 0)
        
        // Recherche du composant audio correspondant √† la description
        guard let component = AudioComponentFindNext(nil, &desc) else {
            print("Composant Audio introuvable")
            return
        }
        
        // Cr√©ation d'une nouvelle instance du composant audio
        var tempUnit: AudioComponentInstance?
        AudioComponentInstanceNew(component, &tempUnit)
        guard let unit = tempUnit else {
            print("√âchec de l'initialisation de l'AudioUnit")
            return
        }
        audioUnit = unit
        
        var one: UInt32 = 1
        
        // Activation de l'entr√©e audio (microphone)
        // Le bus 1 correspond √† l'entr√©e dans le contexte RemoteIO
        AudioUnitSetProperty(unit,
                             kAudioOutputUnitProperty_EnableIO,
                             kAudioUnitScope_Input,
                             1,
                             &one,
                             UInt32(MemoryLayout<UInt32>.size))
        
        // Activation de la sortie audio (haut-parleur)
        // Le bus 0 correspond √† la sortie dans le contexte RemoteIO
        AudioUnitSetProperty(unit,
                             kAudioOutputUnitProperty_EnableIO,
                             kAudioUnitScope_Output,
                             0,
                             &one,
                             UInt32(MemoryLayout<UInt32>.size))
        
        // Configuration du format audio pour l'entr√©e et la sortie
        // Utilisation du format PCM lin√©aire avec des entiers sign√©s
        var streamFormat = AudioStreamBasicDescription(
            mSampleRate: 44100,            // Fr√©quence d'√©chantillonnage en Hz
            mFormatID: kAudioFormatLinearPCM,  // Format PCM lin√©aire
            mFormatFlags: kLinearPCMFormatFlagIsSignedInteger | kAudioFormatFlagIsPacked,
            mBytesPerPacket: 2,            // 2 octets par paquet pour mono 16-bit
            mFramesPerPacket: 1,           // 1 frame par paquet pour PCM
            mBytesPerFrame: 2,             // 2 octets par frame pour mono 16-bit
            mChannelsPerFrame: 1,          // Audio mono (1 canal)
            mBitsPerChannel: 16,           // R√©solution de 16 bits par canal
            mReserved: 0                   // R√©serv√©, doit √™tre 0
        )
        
        // Application du format audio √† la sortie du bus d'entr√©e (microphone)
        AudioUnitSetProperty(unit,
                             kAudioUnitProperty_StreamFormat,
                             kAudioUnitScope_Output,
                             1,
                             &streamFormat,
                             UInt32(MemoryLayout<AudioStreamBasicDescription>.size))
        
        // Application du format audio √† l'entr√©e du bus de sortie (haut-parleur)
        AudioUnitSetProperty(unit,
                             kAudioUnitProperty_StreamFormat,
                             kAudioUnitScope_Input,
                             0,
                             &streamFormat,
                             UInt32(MemoryLayout<AudioStreamBasicDescription>.size))
        
        // Configuration du callback de rendu pour connecter l'entr√©e √† la sortie
        var callbackStruct = AURenderCallbackStruct(
            inputProc: renderCallback,
            inputProcRefCon: UnsafeMutableRawPointer(Unmanaged.passUnretained(self).toOpaque())
        )
        
        // Enregistrement du callback sur l'entr√©e du bus de sortie
        AudioUnitSetProperty(unit,
                             kAudioUnitProperty_SetRenderCallback,
                             kAudioUnitScope_Input,
                             0,
                             &callbackStruct,
                             UInt32(MemoryLayout<AURenderCallbackStruct>.size))
        
        // Initialisation et d√©marrage de l'AudioUnit
        AudioUnitInitialize(unit)
        AudioOutputUnitStart(unit)
    }
    
    /// Taille du buffer audio en octets.
    ///
    /// Cette valeur est utilis√©e comme taille de r√©f√©rence pour les op√©rations de buffer.
    let bufferByteSize: UInt32 = 512
    
    /// Callback de rendu audio appel√© par Core Audio pour obtenir les donn√©es audio.
    ///
    /// Cette fonction:
    /// 1. R√©cup√®re l'instance du gestionnaire audio
    /// 2. Cr√©e un buffer audio pour recevoir les donn√©es du microphone
    /// 3. Appelle AudioUnitRender pour obtenir les donn√©es audio du microphone
    /// 4. Copie les donn√©es audio vers le buffer de sortie
    /// 5. Lib√®re la m√©moire allou√©e pour le buffer temporaire
    ///
    /// - Parameters:
    ///   - inRefCon: R√©f√©rence au contexte utilisateur (instance de AudioLoopbackManager)
    ///   - ioActionFlags: Drapeaux indiquant l'√©tat de l'op√©ration de rendu
    ///   - inTimeStamp: Horodatage des donn√©es audio
    ///   - inBusNumber: Num√©ro du bus audio concern√©
    ///   - inNumberFrames: Nombre de frames audio √† traiter
    ///   - ioData: Structure contenant les buffers de sortie √† remplir
    ///
    /// - Returns: Code d'√©tat OSStatus (noErr en cas de succ√®s)
    private let renderCallback: AURenderCallback = { (
        inRefCon,
        ioActionFlags,
        inTimeStamp,
        inBusNumber,
        inNumberFrames,
        ioData
    ) -> OSStatus in
        
        // R√©cup√©ration de l'instance du gestionnaire audio √† partir du contexte
        let audioManager = Unmanaged<AudioLoopbackManager>.fromOpaque(inRefCon).takeUnretainedValue()
        
        // Calcul de la taille du buffer en fonction du nombre de frames
        let bytesPerFrame: UInt32 = 2 // 16 bits (2 bytes) par frame
        let bufferSize = inNumberFrames * bytesPerFrame
        
        // Cr√©ation d'une structure AudioBufferList pour recevoir les donn√©es du microphone
        var bufferList = AudioBufferList()
        bufferList.mNumberBuffers = 1
        bufferList.mBuffers.mNumberChannels = 1
        bufferList.mBuffers.mDataByteSize = bufferSize
        bufferList.mBuffers.mData = malloc(Int(bufferSize))
        
        // V√©rification que l'allocation m√©moire a r√©ussi
        guard bufferList.mBuffers.mData != nil else {
            print("√âchec d'allocation m√©moire")
            return -1
        }
        
        // Obtention des donn√©es audio du microphone via AudioUnitRender
        let status = AudioUnitRender(audioManager.audioUnit!,
                                     ioActionFlags,
                                     inTimeStamp,
                                     1,
                                     inNumberFrames,
                                     &bufferList)
        
        // V√©rification du statut de l'op√©ration de rendu
        if status != noErr {
            print("Erreur AudioUnitRender: \(status)")
            free(bufferList.mBuffers.mData)
            return status
        }
        
        // Copie des donn√©es audio vers le buffer de sortie si disponible
        if let ioData = ioData {
            // V√©rification que ioData est valide et a au moins un buffer
            if ioData.pointee.mNumberBuffers > 0 {
                memcpy(ioData.pointee.mBuffers.mData, bufferList.mBuffers.mData, Int(bufferList.mBuffers.mDataByteSize))
                ioData.pointee.mBuffers.mDataByteSize = bufferList.mBuffers.mDataByteSize
            }
        }
        
        // Lib√©ration de la m√©moire allou√©e pour le buffer temporaire
        free(bufferList.mBuffers.mData)
        return noErr
    }

    /// Nettoie les ressources audio lors de la destruction de l'instance.
    ///
    /// Arr√™te et d√©sinitialise l'AudioUnit pour lib√©rer les ressources syst√®me.
    deinit {
        if let unit = audioUnit {
            AudioOutputUnitStop(unit)
            AudioUnitUninitialize(unit)
        }
    }
}



struct AudioLoopBackView: View {
    @StateObject private var audioManager = AudioLoopbackManager()
    
    var body: some View {
        VStack {
            Text("üîä Micro vers Haut-parleur")
                .font(.headline)
                .padding()
            Text("AudioToolbox / RemoteIO")
                .font(.subheadline)
        }
    }
}

#Preview {
    AudioLoopBackView()
}
